{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset= https://www.kaggle.com/datasets/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gerekli kütüphaneleri içe aktar\n",
    "import pandas as pd                # Veri analizi ve tablo işlemleri\n",
    "import re                         # Regex ile metin temizliği için\n",
    "import nltk                       # Doğal dil işleme için\n",
    "from sklearn.model_selection import train_test_split   # Eğitim-test ayırma\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Metni sayıya çevirme\n",
    "from sklearn.linear_model import LogisticRegression    # Makine öğrenmesi modeli\n",
    "from sklearn.metrics import accuracy_score, classification_report  # Başarı metrikleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. nltk kütüphanesinden gerekli verileri indir\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stopwords: İngilizce'de anlam taşımayan sık kelimeleri getirir (\"the\", \"is\", \"at\" gibi)\n",
    "\n",
    "lemmatizer: Kelimeleri kök forma indirger (örneğin: playing → play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords                     # İngilizce durak kelimeler (the, and, etc.)\n",
    "from nltk.stem import WordNetLemmatizer               # Kelimeleri kök haline getirme (örn: playing → play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Veriyi oku (Kaggle CSV dosyasını indirip aynı klasöre koymalısın)\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding='latin-1', header=None)\n",
    "\n",
    "# 4. Sütun adlarını tanımla (Kaggle’daki bu dosya sütun ismi içermez)\n",
    "df.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sütun Adı ----> Açıklaması\n",
    "target-->Tweet’in duygusunu (etiketini) gösterir.\n",
    "🔹 0 = Negatif duygu\t\n",
    "🔹 4 = Pozitif duygu\t\n",
    "(Nötr sınıf bu veri setinde yoktur.)\n",
    "id --> Tweet’in benzersiz kimliği (sayısal ID) – genellikle analizde kullanılmaz. \n",
    "\n",
    "date --> Tweet’in atıldığı tarih ve saat bilgisi. |\n",
    "\n",
    "flag-->Veri toplama sırasında kullanılan filtre bilgisi. Çoğunlukla \"NO_QUERY\" şeklindedir. Genellikle önemsizdir. |\n",
    "\n",
    "user-->Tweet’i atan kullanıcının kullanıcı adı. |\n",
    "\n",
    "text-->Tweet’in kendisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Sadece target ve text sütunlarıyla ilgileniyoruz\n",
    "df = df[['target', 'text']]\n",
    "\n",
    "# 6. Target sütununda 0 = negatif, 4 = pozitif\n",
    "# 2 olan nötr verileri kullanmıyoruz, bu veride zaten yok\n",
    "df = df[df['target'].isin([0, 4])]\n",
    "\n",
    "# 7. Etiketleri sadeleştir (0 = 0, 4 = 1)\n",
    "df['label'] = df['target'].map({0: 0, 4: 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read_csv-->Kaggle dosyasını okur (sütun başlığı olmadığından header=None)\n",
    "* df.columns = [...]-->Sütunlara anlamlı isim verir\n",
    "* [['target', 'text']]-->Sadece etiket ve metin sütunlarını alır\n",
    "* df[df['target'].isin([0,4])]-->Sadece pozitif (4) ve negatif (0) tweet'leri seçer\n",
    "* map({0:0, 4:1})-->0 → 0 (negatif), 4 → 1 (pozitif) olarak sadeleştirir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Metin ön işleme için fonksiyon tanımla\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"http\\S+|@\\S+|#[A-Za-z0-9_]+\", \"\", text)  # Link, mention ve hashtag'leri temizle\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \"\", text).lower().split()  # Harf dışı karakterleri sil, küçük harfe çevir\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stop_words]  # Stopword'leri çıkar ve kök halini al\n",
    "    return \" \".join(text)\n",
    "\n",
    "# 9. Tweet metinlerini temizle ve yeni sütuna yaz\n",
    "df['clean_text'] = df['text'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* re.sub(...)-->Tweet içindeki linkleri, etiketleri, sembolleri temizler\n",
    "* lower().split()-->Küçük harfe çevirip kelimelere ayırır\n",
    "* if w not in stop_words-->Gereksiz kelimeleri siler (örnek: the, and, is)\n",
    "* lemmatize-->Kelimeleri kök haline getirir (örnek: loved → love)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Giriş (X) ve hedef (y) verilerini ayır\n",
    "X = df['clean_text']   # Metinler (bağımsız değişken)\n",
    "y = df['label']        # Etiketler (bağımlı değişken: 0 veya 1)\n",
    "\n",
    "# 11. Eğitim ve test verisine böl (%80 eğitim, %20 test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* X: Giriş verisi → tweet’in temiz metni\n",
    "\n",
    "* y: Çıkış/etiket → pozitif mi negatif mi?\n",
    "\n",
    "* train_test_split: Veriyi %80 eğitim, %20 test olacak şekilde böler\n",
    "\n",
    "* random_state: Aynı sonucu alabilmek için sabitlik sağlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. TF-IDF ile metni sayıya çevir (model bunu anlamaz)\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # En çok geçen 5000 kelimeyle sınırlıyoruz\n",
    "X_train_vec = tfidf.fit_transform(X_train)  # Eğitim verisi üzerinden öğren ve dönüştür\n",
    "X_test_vec = tfidf.transform(X_test)        # Test verisini de dönüştür\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF: Kelimelerin önem derecesine göre ağırlık verir\n",
    "\n",
    "* fit_transform: Eğitim verisini öğrenip sayılara çevirir\n",
    "\n",
    "* transform: Test verisini de aynı kurallarla sayıya çevirir\n",
    "\n",
    "* max_features=5000: En çok kullanılan 5000 kelime ile sınırlı tutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13. Modeli oluştur ve eğit\n",
    "model = LogisticRegression()         # Basit ama etkili bir sınıflandırıcı\n",
    "model.fit(X_train_vec, y_train)      # Eğitimi yap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LogisticRegression(): Basit, hızlı ve etkili bir sınıflandırma modeli\n",
    "\n",
    "* .fit(...): Modeli eğitim verisiyle eğitir (tweet → pozitif/negatif ilişkisi öğrenilir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Test verisiyle tahmin yap\n",
    "y_pred = model.predict(X_test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<320000x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1884522 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk Oranı: 0.773496875\n",
      "\n",
      "Sınıflandırma Raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.78      0.75      0.77    159494\n",
      "     Pozitif       0.76      0.79      0.78    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 15. Modelin doğruluğunu ve raporunu yazdır\n",
    "print(\"Doğruluk Oranı:\", accuracy_score(y_test, y_pred))  # Genel başarı oranı\n",
    "print(\"\\nSınıflandırma Raporu:\\n\", classification_report(y_test, y_pred, target_names=[\"Negatif\", \"Pozitif\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* predict(...): Test verisi için pozitif mi negatif mi tahmin eder\n",
    "\n",
    "* accuracy_score: Doğru tahmin yüzdesini hesaplar\n",
    "\n",
    "* classification_report: Precision, recall, F1-score gibi metrikleri verir\n",
    "(her sınıf için ayrı ayrı)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Gerçek Duygu</th>\n",
       "      <th>Tahmin Edilen Duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ahhh hope ok</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool tweet apps razr</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know family drama lamehey next time u hang kim...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>school email wont open geography stuff revise ...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>upper airway problem</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>going miss pastor sermon faith</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lunchdj come eat</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>Pozitif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oh feeling like</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gahh noopeyton need livethis horrible</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thank glad like product review bit site enjoy ...</td>\n",
       "      <td>Pozitif</td>\n",
       "      <td>Pozitif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Gerçek Duygu  \\\n",
       "0                                       ahhh hope ok      Negatif   \n",
       "1                               cool tweet apps razr      Negatif   \n",
       "2  know family drama lamehey next time u hang kim...      Negatif   \n",
       "3  school email wont open geography stuff revise ...      Negatif   \n",
       "4                               upper airway problem      Negatif   \n",
       "5                     going miss pastor sermon faith      Negatif   \n",
       "6                                   lunchdj come eat      Pozitif   \n",
       "7                                    oh feeling like      Negatif   \n",
       "8              gahh noopeyton need livethis horrible      Negatif   \n",
       "9  thank glad like product review bit site enjoy ...      Pozitif   \n",
       "\n",
       "  Tahmin Edilen Duygu  \n",
       "0             Pozitif  \n",
       "1             Pozitif  \n",
       "2             Pozitif  \n",
       "3             Negatif  \n",
       "4             Negatif  \n",
       "5             Negatif  \n",
       "6             Pozitif  \n",
       "7             Negatif  \n",
       "8             Negatif  \n",
       "9             Pozitif  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. İlk 10 test verisini ham metin olarak alalım\n",
    "orijinal_tweetler = X_test[:10].reset_index(drop=True)\n",
    "\n",
    "# 2. Gerçek etiketler ve modelin tahminlerini resetleyerek al\n",
    "gercek = y_test[:10].reset_index(drop=True)\n",
    "tahmin = pd.Series(y_pred[:10])\n",
    "\n",
    "# 3. Her biri için duyguları etiket olarak göster\n",
    "duygu_map = {0: \"Negatif\", 1: \"Pozitif\"}\n",
    "\n",
    "# 4. Hepsini bir tabloya yerleştir\n",
    "sonuc_df = pd.DataFrame({\n",
    "    \"Tweet\": orijinal_tweetler,\n",
    "    \"Gerçek Duygu\": gercek.map(duygu_map),\n",
    "    \"Tahmin Edilen Duygu\": tahmin.map(duygu_map)\n",
    "})\n",
    "\n",
    "# 5. Tabloyu göster\n",
    "sonuc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
